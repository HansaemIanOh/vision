model_config:
  name: 'ddpm'
  input_channels: 3
  learning_rate: 0.0001
  manual_seed: 42
  h_dims:     [3, 64, 128, 256, 512] # 224, 112, 56, 28, 14
  down_index: [0,   1,  1,   1,   1]
  attn_res: [14]
  with_conv: True
  dropout: 0.1
  latent_dim: [3, 224, 224]
  sampling_period: 1
  weight_decay: 0.001
  diffusion_steps: 20
  scheduler_gamma: 0.99
  patch_size: 224 # =*=*=*=*=*=*=*=*=*=*
  grid: 2
  
data_config:
  patch_size: 224 # =*=*=*=*=*=*=*=*=*=*
  data_dir: "data/flowers/train"
  batch_size: 16
  num_workers: 4
  use_manual_split: True


trainer_config:
  accelerator: 'gpu'
  devices: 1  # 2 or [0, 1]
  max_epochs: 2000
  precision: 16-mixed
log_config:
  name: "flower_ddpm"
  save_dir: "logs/"
  check_dir: "logs/check"
  checkpoint: True
  model_summary: False
  
