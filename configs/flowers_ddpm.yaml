model_config:
  name: 'flowers_ddpm'
  input_channels: 3
  learning_rate: 0.0001
  manual_seed: 42
  h_dims: [3, 128, 128, 256, 256] # 224, 112, 56, 28, 14
  patch_size: 224
  attn_res: [14]
  with_conv: True
  dropout: 0.1
  t_max: 1000
  latent_dim: [3, 224, 224]
  sampling_period: 20
  warmup_step: 100


data_config:
  data_dir: "data/flowers/train"
  batch_size: 16
  patch_size: 224
  num_workers: 4
  use_manual_split: True


trainer_config:
  accelerator: 'gpu'
  devices: 4  # 2 or [0, 1]
  max_epochs: 2000

log_config:
  name: "flower_ddpm"
  save_dir: "logs/"
  check_dir: "logs/check"
  checkpoint_path: None
  model_summary: True
  
