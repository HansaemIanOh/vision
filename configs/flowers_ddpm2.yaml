model_config:
  name: 'flowers_ddpm'
  input_channels: 3
  learning_rate: 0.0001
  manual_seed: 42
  h_dims: [3, 128, 256, 512] # 64, 32, 16, 8
  patch_size: 64
  attn_res: [8]
  with_conv: True
  dropout: 0.1
  latent_dim: [3, 224, 224]
  sampling_period: 1
  weight_decay: 0.001
  diffusion_steps: 20

data_config:
  data_dir: "data/flowers/train"
  batch_size: 16
  patch_size: 64
  num_workers: 4
  use_manual_split: True


trainer_config:
  accelerator: 'gpu'
  devices: [1]  # 2 or [0, 1]
  max_epochs: 2000

log_config:
  name: "flower_ddpm"
  save_dir: "logs/"
  check_dir: "logs/check"
  checkpoint_path: None
  model_summary: False
  
